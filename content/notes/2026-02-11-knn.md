---
title: KNN 算法实验记录
date: 2026-02-11
updated: 2026-02-16
excerpt: KNN 算法实验知识总结
categories:
  - slice
---

# 核心内涵速览
K近邻算法，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例，这K个实例的多数属于某个类，就把该输入实例分类到这个类中。

## 需要思考的问题
### 选k
在算法应用中，k怎么确定的，k为多少效果最好呢？所谓的最近邻又是如何来判断给定呢？


- k 一般通过实验来选。


### 测量方法
- 逐像素差的平均欧氏距离
- 余弦相似度

### 预处理方法
- 边缘图代替原始像素值
  - 去除颜色、纹理、光照等变化，只保留形状结构
- 数据白化
- L2 归一化


# Numpy 前置知识

## Axis 的直觉

对于一个**二维矩阵 $(N, D)$**：通常代表 $N$ 个样本，每个样本有 $D$ 个特征。

- **Axis = 0**：沿着“行”的方向（垂直方向）。操作时是“把所有行压扁”。
  
- **Axis = 1**：沿着“列”的方向（水平方向）。操作时是“把所有列压扁”。
  

```python
import numpy as np

# 假设有 3 个样本，每个样本 2 个特征 (3, 2)
X = np.array([
    [1, 2], 
    [3, 4], 
    [5, 6]  
])

# 第一步：平方 np.square(X)
# 结果仍然是 (3, 2)，每个数字都平方了
X2 = X ** 2 
# [[ 1,  4],
#  [ 9, 16],
#  [25, 36]]

# 第二步：按行求和 np.sum(..., axis=1)
# 结果形状变为 (3,) -> 一维数组
row_sum = np.sum(X2, axis=1) 
print(row_sum) 
# 输出: [ 5 25 61]  (即 1+4, 9+16, 25+36)
```

## 切片

`gray = 0.299 * data[:,:,:,0] + ...`

- **概念**：`[` `样本` , `行` , `列` , `通道` `]`
  
- **`:` 的含义**：取该维度上的**所有**元素。
  
```Python

# data[:, :, :, 0] 
# 意思是：取所有图片(:)，所有高(:)，所有宽(:)，但只取第 0 个通道(Red)

# 举例：只取第 5 张图片的中心区域
center_patch = X_train_raw[5, 10:20, 10:20, :] 
```

## 广播机制

如果两个数组的后缘维度（从末尾开始算）的轴长度相符，或其中一方的长度为1，则认为它们是兼容的。

```python
# 测试集样本数 N=3，平方和 (N, 1)
test_sum = np.array([[10], [20], [30]]) # 形状 (3, 1)

# 训练集样本数 M=4，平方和 (1, M)
train_sum = np.array([[1, 2, 3, 4]])    # 形状 (1, 4)

# 魔法发生：(3, 1) + (1, 4) -> (3, 4)
# Numpy 会把 test_sum 复制 4 列，把 train_sum 复制 3 行，然后相加
dist_matrix = test_sum + train_sum

print(dist_matrix)
# 结果 (3, 4):
# [[11, 12, 13, 14],  <- 10 + [1,2,3,4]
#  [21, 22, 23, 24],  <- 20 + [1,2,3,4]
#  [31, 32, 33, 34]]  <- 30 + [1,2,3,4]
```

## 控制张量形状reshape and keepdim

- **Rank-1 Array `(N,)`**：很危险，既不是行向量也不是列向量。
  
- **列向量 `(N, 1)`**：明确的二维矩阵。
  
- **`reshape(-1, 1)`**：`-1` 代表“自动计算”。意思是不管原数组多长，给我变成只有 **1列** 的二维矩阵
  

```python
A = np.array([[1, 2], [3, 4]])

# 不加 keepdims (默认 False)
norm_1 = np.linalg.norm(A, axis=1)
print(norm_1.shape) 
# (2,) -> 退化成了一维数组，如果直接用它除 A (2,2)，可能会发生错误的广播。

# 加 keepdims=True
norm_2 = np.linalg.norm(A, axis=1, keepdims=True)
print(norm_2.shape) 
# (2, 1) -> 保持了二维结构。
# A / norm_2 -> (2,2) / (2,1) -> 完美兼容，每一行除以该行的模长。
```



# 各种定义和代码实现
## 训练集，验证集，测试集

* **训练集 (Training)**：**你的课本。** 占 60%-80%。你在这里反复磨练，允许犯错，目的是为了记住规律。
* **验证集 (Validation)**：**你的模拟考。** 占 10%-20%。用来调整参数（比如 k-NN 里的  取几）。它是“教练”，告诉你哪里需要微调。
* **测试集 (Test)**：**你的高考。** 占 10%-20%。它是“考官”，一旦碰到它，你就不能再改任何参数了，它是最后的终极真相。


##  计算距离


在图片空间中，设两张图像 $X, Y \in \mathbb{R}^{H \times W \times C}$（$H$: 高度, $W$: 宽度, $C$: 通道数）

其 **L1 距离** 定义为：

$$
d_{\text{L1}}(X, Y) = \|X - Y\|_1 = \sum_{h=1}^{H} \sum_{w=1}^{W} \sum_{c=1}^{C} \bigl| X_{h,w,c} - Y_{h,w,c} \bigr|
$$

等价地，将图像展平为向量 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^{HWC}$ 后：

$$
d_{\text{L1}}(X, Y) = \|\mathbf{x} - \mathbf{y}\|_1 = \sum_{i=1}^{HWC} |x_i - y_i|
$$

此即曼哈顿距离，衡量两张图像在像素级的绝对差异之和，对异常值比 L2 距离更鲁棒。

```python
num_test = X.shape[0]
num_train = self.X_train.shape[0]
dists = np.zeros((num_test, num_train)) 
# L1 距离只能用循环（或大量内存），这里为了稳妥用循环
for i in range(num_test):
    dists[i, :] = np.sum(np.abs(self.X_train - X[i, :]), axis=1)
```
1. 初始化

   - **`num_test` & `num_train`**: 分别获取测试集样本数 $N$ 和训练集样本数 $M$。
  
    - **`np.zeros((num_test, num_train))`**: 预先分配一个形状为 $(N, M)$ 的全零矩阵 `dists`，用于存储最终的距离结果。
  

2. `for i in range(num_test):`

    - **外层循环**: 遍历每一个测试样本。如果测试集有 $N$ 条数据，这个循环就会执行 $N$ 次。
    

3. `self.X_train - X[i, :]` (核心计算)

    - **广播机制 (Broadcasting)**:
  
      - `X[i, :]` 的形状是 $(D,)$，代表第 $i$ 个测试样本。
    
      - `self.X_train` 的形状是 $(M, D)$。
    
      - 当两者相减时，NumPy 会自动将 `X[i, :]` 复制 $M$ 次，使其形状匹配。计算结果是一个 $(M, D)$ 的矩阵，表示第 $i$ 个测试样本与**所有**训练样本在每个维度上的差值。
    

4. `np.sum(np.abs(...), axis=1)`

      - **`np.abs(...)`**: 对上一步得到的差值矩阵取绝对值。
  
      - **`axis=1`**: 沿着特征维度（横向）进行求和。
  
        - 计算结果是一个长度为 $M$ 的一维数组。
    
        - 这个数组的第 $j$ 个元素就是 $X[i]$ 与 $X_{train}[j]$ 之间的 L1 距离。
    

5. `dists[i, :] = ...`

    - 将计算出的 $M$ 个距离值填入 `dists` 矩阵的第 $i$ 行。

---

其 **L2 距离** 定义为：

$$
d_{\text{L2}}(X, Y) = \|X - Y\|_2 = \sqrt{\sum_{h=1}^{H} \sum_{w=1}^{W} \sum_{c=1}^{C} \bigl( X_{h,w,c} - Y_{h,w,c} \bigr)^2}
$$

等价地，将图像展平为向量 $\mathbf{x}, \mathbf{y} \in \mathbb{R}^{HWC}$ 后：

$$
d_{\text{L2}}(X, Y) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{(\mathbf{x} - \mathbf{y})^\top (\mathbf{x} - \mathbf{y})}
$$

此即欧几里得范数诱导的度量，衡量两张图像在像素级的全局差异。
```python
num_test = X.shape[0]
num_train = self.X_train.shape[0]
dists = np.zeros((num_test, num_train)) 
      
# 使用向量化公式：(x-y)^2 = x^2 + y^2 - 2xy 加速计算
test_sum = np.sum(np.square(X), axis=1).reshape(-1, 1)
train_sum = np.sum(np.square(self.X_train), axis=1).reshape(1, -1)
inner_product = np.dot(X, self.X_train.T)
dists = np.sqrt(np.maximum(0, test_sum + train_sum - 2 * inner_product))        
```
1. `np.sum(np.square(X), axis=1)`:
  
   - 算出测试集每个样本的模长平方 $\|\mathbf{x}\|^2$。这里是对每个元素求平方。
    
   - 形状 `(N,)`。
    
2. `.reshape(-1, 1)`:
  
   - 把形状变成 `(N, 1)`（立起来），准备利用广播机制。
3. `.reshape(1, -1)`:
  
   - 把训练集的模长平方 $\|\mathbf{y}\|^2$ 变成 `(1, M)`（横过来）。
4. `np.dot(X, self.X_train.T)`:
  
   - 这是矩阵乘法。$(N, D) \times (D, M) \to (N, M)$。
    
   - 算出了所有 $\mathbf{x} \cdot \mathbf{y}$。
    
5. `test_sum + train_sum - 2 * inner_product`:
  
   - 这是核心。利用广播：
    
   - $(N, 1) + (1, M) \to (N, M)$
    
   - $(N, M) - (N, M) \to (N, M)$
    
   - 完全展开了公式 $(x-y)^2 = x^2 + y^2 - 2xy$。
    
6. `np.maximum(0, ...)`:
  
   - **数值稳定性**。理论上平方数不可能小于0。但计算机浮点运算会有微小误差（比如算出 -0.000000001）。
    
   - 如果对负数开根号 `np.sqrt` 会报错 (NaN)。这行代码是“兜底”的。


---

其 **余弦距离** 定义为：

$$
d_{\cos}(X, Y) = 1 - \frac{\displaystyle\sum_{h=1}^{H} \sum_{w=1}^{W} \sum_{c=1}^{C} X_{h,w,c} \, Y_{h,w,c}}
{\sqrt{\displaystyle\sum_{h=1}^{H} \sum_{w=1}^{W} \sum_{c=1}^{C} X_{h,w,c}^2} \;
 \sqrt{\displaystyle\sum_{h=1}^{H} \sum_{w=1}^{W} \sum_{c=1}^{C} Y_{h,w,c}^2}}
$$

等价地（向量形式）：
$$
d_{\cos}(X, Y) = 1 - \frac{\mathbf{x}^\top \mathbf{y}}{\|\mathbf{x}\|_2 \, \|\mathbf{y}\|_2}
$$

取值范围 $[0, 2]$：值越小表示图像内容结构越相似（对整体亮度/对比度缩放不敏感）。

```python
num_test = X.shape[0]
num_train = self.X_train.shape[0]
dists = np.zeros((num_test, num_train)) 

# 余弦距离 = 1 - Cosine Similarity
# 先归一化向量，防止除零加一个极小值
X_norm = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-8)
Train_norm = self.X_train / (np.linalg.norm(self.X_train, axis=1, keepdims=True) + 1e-8)
similarity = np.dot(X_norm, Train_norm.T)
dists = 1.0 - similarity            
```
1. 向量归一化 (L2 Normalization)

   - **`np.linalg.norm(X, axis=1, keepdims=True)`**:
  
     - 计算每个样本向量的模长（L2 范数）。
    
     - `keepdims=True` 确保结果形状为 $(N, 1)$，这样才能利用**广播机制**对原矩阵进行按行除法。
    
   - **`+ 1e-8` (数值稳定性)**:
     - 这是一个“安全网”。如果某个向量全为 0，其模长也为 0。除以 0 会导致程序崩溃或产生 `NaN`。加上一个极小值（Epsilon）可以确保计算安全。
     - **`X_norm` & `Train_norm`**: 归一化后的向量模长均为 1。这意味着后续的内积计算直接等同于余弦相似度。
  

2. `np.dot(X_norm, Train_norm.T)` (核心计算)

   - **矩阵乘法**: 将形状为 $(N, D)$ 的测试集与形状为 $(D, M)$ 的训练集转置相乘
   - **物理意义**: 结果矩阵 `similarity` 中坐标为 $(i, j)$ 的元素，就是归一化向量 $\mathbf{\hat{x}}_i$ 与 $\mathbf{\hat{y}}_j$ 的点积：
        - $\text{similarity}_{ij} = \mathbf{\hat{x}}_i \cdot \mathbf{\hat{y}}_j = \frac{\mathbf{x}_i \cdot \mathbf{y}_j}{\|\mathbf{x}_i\| \|\mathbf{y}_j\|}$

## 预处理方法

### 构造边缘图
设原始图像 $I \in \mathbb{R}^{H \times W \times C}$（$C \geq 1$ 为通道数）。通过边缘检测算子 $\mathcal{E}: \mathbb{R}^{H \times W \times C} \to \mathbb{R}^{H \times W}$，将其映射为**边缘图** $E = \mathcal{E}(I)$，定义为：

$$
E_{h,w} = \left\| \nabla I_{\text{gray}}(h,w) \right\|_2
= \sqrt{ \left( \frac{\partial I_{\text{gray}}}{\partial x} \right)^2 + \left( \frac{\partial I_{\text{gray}}}{\partial y} \right)^2 }
$$

其中：
- $I_{\text{gray}} \in \mathbb{R}^{H \times W}$ 为灰度化图像（如 $I_{\text{gray}} = 0.299 I_R + 0.587 I_G + 0.114 I_B$），
- $\nabla$ 为梯度算子（常用 Sobel、Scharr 等离散近似）。

---

-  关键性质
   1. **去除颜色**：通过灰度化 $I \to I_{\text{gray}}$ 消除通道差异。
   2. **去除光照**：梯度 $\nabla I_{\text{gray}}$ 对全局亮度偏移 $\Delta$ 不敏感（$\nabla    (I_{\text{gray}} + \Delta) = \nabla I_{\text{gray}}$）。
   3. **抑制纹理**：边缘检测聚焦**显著梯度变化**（物体边界），平滑区域与高频纹理被抑制。
   4. **保留形状**：$E$ 仅编码图像中**强度突变的位置与方向**，即物体轮廓与结构。

>  边缘图 $E$ 是原始图像的**几何结构表示**，对颜色、光照、均匀纹理变化具有不变性。

```python
def get_edges(data):
    # 转灰度
    gray = 0.299 * data[:,:,:,0] + 0.587 * data[:,:,:,1] + 0.114 * data[:,:,:,2]
    edges = np.zeros_like(gray)
    for i in range(len(gray)):
        sx = ndimage.sobel(gray[i], axis=0)
        sy = ndimage.sobel(gray[i], axis=1)
        edges[i] = np.hypot(sx, sy)
    return edges.reshape(data.shape[0], -1)
    
return get_edges(X_train_raw), get_edges(X_query_raw)
```

1. 灰度化处理 (Grayscale Conversion)

```python
gray = 0.299 * data[:,:,:,0] + 0.587 * data[:,:,:,1] + 0.114 * data[:,:,:,2]
```

2. Sobel 算子梯度计算 (Sobel Filter)

```python
sx = ndimage.sobel(gray[i], axis=0) # 垂直梯度
sy = ndimage.sobel(gray[i], axis=1) # 水平梯度
```

- **操作**：对每一张灰度图应用 **Sobel 算子**。
  
- **物理意义**：
  
  - `sx` 检测图像中**水平方向**的边缘（亮度在垂直方向的变化）。
    
  - `sy` 检测图像中**垂直方向**的边缘（亮度在水平方向的变化）。
    
- **本质**：它是离散型的导数计算，通过卷积核识别像素值剧烈变化的地方（即边缘）。
  


3. 计算边缘强度 (Magnitude)

```python
edges[i] = np.hypot(sx, sy)
```

- **公式**：`np.hypot(x, y)` 计算的是 $\sqrt{sx^2 + sy^2}$。
  
- **目的**：将两个方向的梯度结合起来，得到该像素点总的**边缘强度**。无论边缘是横着的、竖着的还是斜着的，都会被捕捉到。

### 数据白化

设数据矩阵 $\mathbf{X} \in \mathbb{R}^{n \times d}$（$n$ 个样本，$d$ 维特征），**白化**是线性变换：

$$
\mathbf{Z} = (\mathbf{X} - \boldsymbol{\mu}) \mathbf{W}, \quad \text{满足} \quad \frac{1}{n} \mathbf{Z}^\top \mathbf{Z} = \mathbf{I}_d
$$

其中：
- $\boldsymbol{\mu} = \frac{1}{n} \sum_{i=1}^n \mathbf{x}_i$（样本均值向量）
- $\mathbf{W} = \mathbf{U} \mathbf{\Lambda}^{-1/2} \mathbf{U}^\top$（ZCA白化矩阵）
- $\mathbf{\Sigma} = \frac{1}{n} (\mathbf{X} - \boldsymbol{\mu})^\top (\mathbf{X} - \boldsymbol{\mu}) = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^\top$（协方差矩阵的特征分解）

**效果**：白化后数据 $\mathbf{Z}$ 满足：
- 零均值：$\mathbb{E}[\mathbf{z}] = \mathbf{0}$
- 单位方差：$\operatorname{Var}(z_j) = 1$
- 无相关性：$\operatorname{Cov}(z_j, z_k) = 0 \;(j \neq k)$
```python
# PCA 白化
X_tr = X_tr / 255.0
X_query = X_query / 255.0
# 计算均值并去中心化
mean = np.mean(X_tr, axis=0)
X_tr -= mean
X_query -= mean # 注意：测试集也要减去训练集的均值

# PCA 降维并白化 (保留 95% 方差以节省计算)
pca = PCA(n_components=0.95, whiten=True)
X_tr_white = pca.fit_transform(X_tr)
X_query_white = pca.transform(X_query)
return X_tr_white, X_query_white------
解释上面代码
```

1.去中心化 (Zero-centering)

```python
mean = np.mean(X_tr, axis=0)
X_tr -= mean
X_query -= mean 
```

- **操作**：计算训练集每个特征（像素点）的平均值，然后从训练集和测试集中减去它。
  
- **目的**：将数据的中心移到坐标原点。这对于 PCA 非常重要，因为 PCA 是基于方差（即数据围绕中心散布的程度）来寻找主成分的。
  
- **注意点**：**必须使用训练集的均值来处理测试集**。这是为了模拟真实情况：在模型上线前，你无法预知未来的测试数据长什么样。
  

2. PCA 降维 (`n_components=0.95`)
  

```python
pca = PCA(n_components=0.95, ...)
```

- 寻找能够解释数据 95% 方差的主成分。图片像素之间存在大量冗余（比如相邻像素通常颜色接近）。PCA 会找到一组新的正交基，将数据投影到这些轴上。
  
- **意义**：
  
  - **压缩**：不再保留全部 3072 个维度，而是只保留最重要的那些（通常只需几百个维度就能达到 95% 的信息量）。
    
  - **去噪**：最后 5% 的方差通常被认为是随机噪声，丢弃它们反而能提高模型泛化能力。
    

3. 白化处理 (`whiten=True`)
  

```Python
pca = PCA(..., whiten=True)
```

- **操作**：在投影到主成分轴后，对每个轴上的数据进行缩放，使其方差统一为 1。
  
- **物理意义**：
  
  - **消除相关性**：使得处理后的特征之间彼此独立（协方差矩阵变为单位阵）。
    
  - **特征平等化**：确保模型不会因为某个特征的数值范围大（方差大）而过度关注它。
    

4. `fit_transform` vs `transform`
  

```Python
X_tr_white = pca.fit_transform(X_tr)
X_query_white = pca.transform(X_query)
```

- **`fit_transform`**：在训练集上“学习”映射规则（计算特征向量和特征值），并立即应用。
  
- **`transform`**：**严禁用测试集 fit**。这里直接套用训练集学到的投影矩阵，保证了训练和测试在同一个特征空间内。
### L2 归一化

**定义**：  
对非零向量 $\mathbf{x} = [x_1, x_2, \dots, x_n]^\top \in \mathbb{R}^n$，其 **L2 归一化** 定义为：
$$
\hat{\mathbf{x}} = \frac{\mathbf{x}}{\|\mathbf{x}\|_2}, \quad \text{其中} \quad \|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2} > 0
$$
归一化后满足 $\|\hat{\mathbf{x}}\|_2 = 1$。


- 关键性质
- 保持方向不变：$\hat{\mathbf{x}}$ 与 $\mathbf{x}$ 共线（$\hat{\mathbf{x}} = k\mathbf{x},\ k>0$）。
- 仅当 $\mathbf{x} \neq \mathbf{0}$ 时定义（零向量无 L2 归一化）。
- 广泛应用于机器学习（如特征标准化、余弦相似度计算）。

```python
 # 1. 展平 (Flatten): (N, 32, 32, 3) -> (N, 3072)
 X_tr = X_train_raw.reshape(X_train_raw.shape[0], -1)
 X_query = X_query_raw.reshape(X_query_raw.shape[0], -1)
 X_tr = X_tr / 255.0
 X_query = X_query / 255.0
 X_tr /= (np.linalg.norm(X_tr, axis=1, keepdims=True) + 1e-8)
 X_query /= (np.linalg.norm(X_query, axis=1, keepdims=True) + 1e-8)
```
